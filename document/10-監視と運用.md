# 10 - ç›£è¦–ã¨é‹ç”¨

> [[09-ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼]] | [[BondPointè¨­è¨ˆæ›¸]] | Next: [[11-é–‹ç™ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«]]

## ğŸ“Š ç›£è¦–æˆ¦ç•¥

### ç›£è¦–ã®4ã¤ã®æŸ±

```
ğŸ” ãƒ¡ãƒˆãƒªã‚¯ã‚¹     ğŸ“‹ ãƒ­ã‚°
â”œâ”€ ã‚·ã‚¹ãƒ†ãƒ       â”œâ”€ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
â”œâ”€ ã‚¢ãƒ—ãƒª        â”œâ”€ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£
â”œâ”€ ãƒ“ã‚¸ãƒã‚¹      â”œâ”€ ç›£æŸ»
â””â”€ ãƒ¦ãƒ¼ã‚¶ãƒ¼      â””â”€ ã‚¨ãƒ©ãƒ¼

ğŸ“ˆ ãƒˆãƒ¬ãƒ¼ã‚¹      ğŸš¨ ã‚¢ãƒ©ãƒ¼ãƒˆ
â”œâ”€ åˆ†æ•£è¿½è·¡      â”œâ”€ ã—ãã„å€¤
â”œâ”€ ä¾å­˜é–¢ä¿‚      â”œâ”€ ç•°å¸¸æ¤œçŸ¥
â”œâ”€ ãƒœãƒˆãƒ«ãƒãƒƒã‚¯  â”œâ”€ é€šçŸ¥
â””â”€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ â””â”€ ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
```

---

## ğŸ“ˆ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–

### ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹

#### Cloud Run ãƒ¡ãƒˆãƒªã‚¯ã‚¹

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | ã—ãã„å€¤ | ã‚¢ãƒ©ãƒ¼ãƒˆ | å¯¾å¿œ |
|------------|----------|----------|------|
| **CPUä½¿ç”¨ç‡** | > 80% | Warning | ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒ«ç¢ºèª |
| **ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡** | > 85% | Warning | ãƒ¡ãƒ¢ãƒªåˆ¶é™è¦‹ç›´ã— |
| **ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°/ç§’** | > 1000 | Info | ã‚¹ã‚±ãƒ¼ãƒ«çŠ¶æ³ç¢ºèª |
| **ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ P95** | > 1ç§’ | Critical | ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹èª¿æŸ» |
| **ã‚¨ãƒ©ãƒ¼ç‡** | > 1% | Critical | ç·Šæ€¥å¯¾å¿œ |
| **èµ·å‹•æ™‚é–“** | > 10ç§’ | Warning | ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆå¯¾ç­– |

#### Cloud SQL ãƒ¡ãƒˆãƒªã‚¯ã‚¹

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | ã—ãã„å€¤ | ã‚¢ãƒ©ãƒ¼ãƒˆ | å¯¾å¿œ |
|------------|----------|----------|------|
| **æ¥ç¶šæ•°** | > 80% | Warning | æ¥ç¶šãƒ—ãƒ¼ãƒ«èª¿æ•´ |
| **CPUä½¿ç”¨ç‡** | > 80% | Warning | ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ‹¡å¼µ |
| **ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡** | > 90% | Critical | ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ‹¡å¼µ |
| **ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é…å»¶** | > 5ç§’ | Warning | ãƒ¬ãƒ—ãƒªã‚«ç¢ºèª |
| **ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒª** | > 1ç§’ | Warning | ã‚¯ã‚¨ãƒªæœ€é©åŒ– |

### ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¡ãƒˆãƒªã‚¯ã‚¹

#### ãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹

```python
from prometheus_client import Counter, Histogram, Gauge
import time

# ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®šç¾©
status_updates_total = Counter(
    'bondpoint_status_updates_total',
    'Total number of status updates',
    ['status_type', 'user_id']
)

status_update_duration = Histogram(
    'bondpoint_status_update_duration_seconds',
    'Time spent processing status updates'
)

active_users = Gauge(
    'bondpoint_active_users',
    'Number of currently active users'
)

firestore_sync_errors = Counter(
    'bondpoint_firestore_sync_errors_total',
    'Total number of Firestore sync errors'
)

class MetricsCollector:
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""

    @staticmethod
    def record_status_update(status_type: str, user_id: str, duration: float):
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
        status_updates_total.labels(
            status_type=status_type,
            user_id=user_id
        ).inc()

        status_update_duration.observe(duration)

    @staticmethod
    def update_active_users(count: int):
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°æ›´æ–°"""
        active_users.set(count)

    @staticmethod
    def record_sync_error(error_type: str):
        """åŒæœŸã‚¨ãƒ©ãƒ¼è¨˜éŒ²"""
        firestore_sync_errors.labels(error_type=error_type).inc()

# ä½¿ç”¨ä¾‹
async def update_user_status(event_id: str, user_id: str, status_data: dict):
    start_time = time.time()

    try:
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°å‡¦ç†
        result = await process_status_update(event_id, user_id, status_data)

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
        duration = time.time() - start_time
        MetricsCollector.record_status_update(
            status_data['status_type'],
            user_id,
            duration
        )

        return result

    except FirestoreSyncError as e:
        MetricsCollector.record_sync_error("firestore_sync")
        raise
```

### ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹

#### React Native ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

```typescript
import analytics from '@react-native-firebase/analytics';
import perf from '@react-native-firebase/perf';

class UXMetrics {
  /**
   * ç”»é¢èª­ã¿è¾¼ã¿æ™‚é–“æ¸¬å®š
   */
  static async measureScreenLoad(screenName: string) {
    const trace = perf().newTrace(`screen_load_${screenName}`);
    await trace.start();

    // ç”»é¢èª­ã¿è¾¼ã¿å®Œäº†æ™‚
    await trace.stop();
  }

  /**
   * ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“
   */
  static async measureStatusUpdate(statusType: string) {
    const startTime = Date.now();

    try {
      await updateStatus(statusType);

      const duration = Date.now() - startTime;

      // Firebase Analytics ã«è¨˜éŒ²
      await analytics().logEvent('status_update_performance', {
        status_type: statusType,
        duration_ms: duration,
        success: true
      });

    } catch (error) {
      const duration = Date.now() - startTime;

      await analytics().logEvent('status_update_performance', {
        status_type: statusType,
        duration_ms: duration,
        success: false,
        error_type: error.type
      });
    }
  }

  /**
   * ã‚¢ãƒ—ãƒªã‚¯ãƒ©ãƒƒã‚·ãƒ¥è¿½è·¡
   */
  static reportCrash(error: Error, screen: string) {
    analytics().logEvent('app_crash', {
      error_message: error.message,
      screen_name: screen,
      timestamp: Date.now()
    });
  }
}
```

---

## ğŸ“‹ ãƒ­ã‚°ç®¡ç†

### æ§‹é€ åŒ–ãƒ­ã‚°

#### ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«å®šç¾©

| ãƒ¬ãƒ™ãƒ« | ç”¨é€” | ä¾‹ | ä¿æŒæœŸé–“ |
|--------|------|----|---------|
| **DEBUG** | é–‹ç™ºæ™‚è©³ç´°æƒ…å ± | é–¢æ•°å‘¼ã³å‡ºã—ã€å¤‰æ•°å€¤ | 7æ—¥ |
| **INFO** | ä¸€èˆ¬çš„ãªæƒ…å ± | APIå‘¼ã³å‡ºã—ã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¤‰æ›´ | 30æ—¥ |
| **WARNING** | æ³¨æ„ãŒå¿…è¦ãªçŠ¶æ³ | é…å»¶ã€ãƒªãƒˆãƒ©ã‚¤ | 90æ—¥ |
| **ERROR** | ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ | ä¾‹å¤–ã€å¤±æ•— | 1å¹´ |
| **CRITICAL** | ã‚·ã‚¹ãƒ†ãƒ åœæ­¢ãƒ¬ãƒ™ãƒ« | ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢ã€ãƒ‡ãƒ¼ã‚¿ç ´æ | æ°¸ç¶š |

#### ãƒ­ã‚°å½¢å¼æ¨™æº–åŒ–

```python
import logging
import json
from datetime import datetime
from typing import Optional

class StructuredLogger:
    """æ§‹é€ åŒ–ãƒ­ã‚°å‡ºåŠ›"""

    def __init__(self, service_name: str):
        self.service_name = service_name
        self.logger = logging.getLogger(service_name)

    def log(
        self,
        level: str,
        message: str,
        user_id: Optional[str] = None,
        event_id: Optional[str] = None,
        trace_id: Optional[str] = None,
        **kwargs
    ):
        """æ§‹é€ åŒ–ãƒ­ã‚°å‡ºåŠ›"""
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "severity": level.upper(),
            "service": self.service_name,
            "message": message,
            "trace_id": trace_id,
            "user_id": user_id,
            "event_id": event_id,
            **kwargs
        }

        # JSONå½¢å¼ã§å‡ºåŠ›ï¼ˆCloud Loggingå‘ã‘ï¼‰
        self.logger.log(
            getattr(logging, level.upper()),
            json.dumps(log_entry, ensure_ascii=False)
        )

    def info_status_update(
        self,
        user_id: str,
        event_id: str,
        old_status: str,
        new_status: str,
        trace_id: str
    ):
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°ãƒ­ã‚°"""
        self.log(
            "info",
            "User status updated",
            user_id=user_id,
            event_id=event_id,
            trace_id=trace_id,
            old_status=old_status,
            new_status=new_status,
            operation="status_update"
        )

    def error_firestore_sync(
        self,
        user_id: str,
        event_id: str,
        error: Exception,
        trace_id: str
    ):
        """FirestoreåŒæœŸã‚¨ãƒ©ãƒ¼ãƒ­ã‚°"""
        self.log(
            "error",
            "Firestore sync failed",
            user_id=user_id,
            event_id=event_id,
            trace_id=trace_id,
            error_type=type(error).__name__,
            error_message=str(error),
            operation="firestore_sync"
        )

# ä½¿ç”¨ä¾‹
logger = StructuredLogger("bondpoint-api")

async def update_user_status(event_id: str, user_id: str, status_data: dict):
    trace_id = generate_trace_id()

    try:
        old_status = await get_current_status(event_id, user_id)
        new_status = await save_status(event_id, user_id, status_data)

        # æˆåŠŸãƒ­ã‚°
        logger.info_status_update(
            user_id, event_id,
            old_status.status_type if old_status else None,
            new_status.status_type,
            trace_id
        )

        return new_status

    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
        logger.error_firestore_sync(user_id, event_id, e, trace_id)
        raise
```

### ãƒ­ã‚°æ¤œç´¢ãƒ»åˆ†æ

#### BigQuery ãƒ­ã‚°åˆ†æ

```sql
-- ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
SELECT
  JSON_EXTRACT_SCALAR(jsonPayload, '$.user_id') as user_id,
  JSON_EXTRACT_SCALAR(jsonPayload, '$.old_status') as old_status,
  JSON_EXTRACT_SCALAR(jsonPayload, '$.new_status') as new_status,
  TIMESTAMP_DIFF(
    timestamp,
    LAG(timestamp) OVER (
      PARTITION BY JSON_EXTRACT_SCALAR(jsonPayload, '$.user_id')
      ORDER BY timestamp
    ),
    MILLISECOND
  ) as update_interval_ms
FROM `bondpoint.logs.cloudrun`
WHERE
  DATE(timestamp) = CURRENT_DATE()
  AND JSON_EXTRACT_SCALAR(jsonPayload, '$.operation') = 'status_update'
  AND severity = 'INFO'
ORDER BY timestamp DESC;

-- ã‚¨ãƒ©ãƒ¼ç‡åˆ†æ
SELECT
  DATE(timestamp) as date,
  COUNT(*) as total_requests,
  COUNTIF(severity = 'ERROR') as error_count,
  ROUND(COUNTIF(severity = 'ERROR') / COUNT(*) * 100, 2) as error_rate_percent
FROM `bondpoint.logs.cloudrun`
WHERE
  DATE(timestamp) >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)
GROUP BY date
ORDER BY date DESC;

-- ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œå‹•åˆ†æ
SELECT
  JSON_EXTRACT_SCALAR(jsonPayload, '$.new_status') as status_type,
  COUNT(*) as update_count,
  COUNT(DISTINCT JSON_EXTRACT_SCALAR(jsonPayload, '$.user_id')) as unique_users,
  ROUND(AVG(TIMESTAMP_DIFF(
    LEAD(timestamp) OVER (
      PARTITION BY JSON_EXTRACT_SCALAR(jsonPayload, '$.user_id')
      ORDER BY timestamp
    ),
    timestamp,
    SECOND
  )), 2) as avg_duration_seconds
FROM `bondpoint.logs.cloudrun`
WHERE
  DATE(timestamp) = CURRENT_DATE()
  AND JSON_EXTRACT_SCALAR(jsonPayload, '$.operation') = 'status_update'
GROUP BY status_type
ORDER BY update_count DESC;
```

---

## ğŸš¨ ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ 

### ã‚¢ãƒ©ãƒ¼ãƒˆéšå±¤

#### ãƒ¬ãƒ™ãƒ«åˆ¥å¯¾å¿œ

| ãƒ¬ãƒ™ãƒ« | é€šçŸ¥å…ˆ | å¯¾å¿œæ™‚é–“ | ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ |
|--------|--------|----------|------------------|
| **Info** | Slack | - | ãªã— |
| **Warning** | Slack + Email | 30åˆ† | 1æ™‚é–“å¾Œã«ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ãƒˆ |
| **Critical** | Slack + Email + SMS | 5åˆ† | 15åˆ†å¾Œã«ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ãƒˆ |
| **Emergency** | å…¨ãƒãƒ£ãƒãƒ« + é›»è©± | å³åº§ | 5åˆ†å¾Œã«ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ |

#### ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«

```yaml
# Cloud Monitoring ã‚¢ãƒ©ãƒ¼ãƒˆãƒãƒªã‚·ãƒ¼
api_error_rate:
  condition:
    metric: "compute.googleapis.com/instance/cpu/utilization"
    filter: 'resource.type="gce_instance"'
    threshold: 0.8
    duration: 300s
  notification:
    - slack-channel: "#alerts"
    - email: "dev-team@bondpoint.com"

status_update_latency:
  condition:
    metric: "custom.googleapis.com/status_update_duration"
    aggregation: "95th percentile"
    threshold: 2.0
    duration: 180s
  notification:
    - slack-channel: "#performance"

firestore_sync_errors:
  condition:
    metric: "custom.googleapis.com/firestore_sync_errors"
    rate: "> 10/minute"
    duration: 60s
  severity: "critical"
  notification:
    - slack-channel: "#alerts"
    - email: "oncall@bondpoint.com"
    - sms: "+81-80-1234-5678"
```

### ç•°å¸¸æ¤œçŸ¥

#### æ©Ÿæ¢°å­¦ç¿’ãƒ™ãƒ¼ã‚¹æ¤œçŸ¥

```python
from sklearn.ensemble import IsolationForest
import numpy as np

class AnomalyDetector:
    """ç•°å¸¸æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.model = IsolationForest(contamination=0.1)
        self.is_trained = False

    def train(self, normal_data: np.ndarray):
        """æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        self.model.fit(normal_data)
        self.is_trained = True

    def detect_anomaly(self, metrics: dict) -> bool:
        """ç•°å¸¸æ¤œçŸ¥"""
        if not self.is_trained:
            return False

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›
        features = np.array([
            metrics['response_time'],
            metrics['error_rate'],
            metrics['request_count'],
            metrics['cpu_usage'],
            metrics['memory_usage']
        ]).reshape(1, -1)

        # ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—
        anomaly_score = self.model.decision_function(features)[0]

        # ã—ãã„å€¤ã«ã‚ˆã‚‹åˆ¤å®š
        return anomaly_score < -0.5

# ä½¿ç”¨ä¾‹
anomaly_detector = AnomalyDetector()

async def check_system_health():
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    current_metrics = {
        'response_time': await get_avg_response_time(),
        'error_rate': await get_error_rate(),
        'request_count': await get_request_count(),
        'cpu_usage': await get_cpu_usage(),
        'memory_usage': await get_memory_usage()
    }

    if anomaly_detector.detect_anomaly(current_metrics):
        await send_anomaly_alert(current_metrics)
```

---

## ğŸ› ï¸ é‹ç”¨ãƒ—ãƒ­ã‚»ã‚¹

### ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œ

#### ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆåˆ†é¡

| é‡è¦åº¦ | å®šç¾© | ç›®æ¨™å¯¾å¿œæ™‚é–“ | ä¾‹ |
|--------|------|-------------|-----|
| **P0** | ã‚µãƒ¼ãƒ“ã‚¹å…¨åœæ­¢ | 15åˆ† | APIå®Œå…¨åœæ­¢ã€ãƒ‡ãƒ¼ã‚¿æ¶ˆå¤± |
| **P1** | ä¸»è¦æ©Ÿèƒ½åœæ­¢ | 1æ™‚é–“ | ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°ä¸å¯ |
| **P2** | ä¸€éƒ¨æ©Ÿèƒ½å½±éŸ¿ | 4æ™‚é–“ | ä½ç½®æƒ…å ±è¡¨ç¤ºç•°å¸¸ |
| **P3** | è»½å¾®ãªå•é¡Œ | 24æ™‚é–“ | UIè¡¨ç¤ºå´©ã‚Œ |

#### å¯¾å¿œãƒ•ãƒ­ãƒ¼

```
ğŸ” æ¤œçŸ¥
â”œâ”€ è‡ªå‹•ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
â”œâ”€ ãƒ¦ãƒ¼ã‚¶ãƒ¼å ±å‘Š
â””â”€ å®šæœŸãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    â”‚
    â†“
ğŸš¨ ãƒˆãƒªã‚¢ãƒ¼ã‚¸
â”œâ”€ é‡è¦åº¦åˆ¤å®š
â”œâ”€ å½±éŸ¿ç¯„å›²ç¢ºèª
â””â”€ æ‹…å½“è€…ã‚¢ã‚µã‚¤ãƒ³
    â”‚
    â†“
ğŸ”§ å¯¾å¿œ
â”œâ”€ å¿œæ€¥å‡¦ç½®
â”œâ”€ æ ¹æœ¬åŸå› èª¿æŸ»
â””â”€ ä¿®æ­£å®Ÿè£…
    â”‚
    â†“
âœ… è§£æ±º
â”œâ”€ æ©Ÿèƒ½å›å¾©ç¢ºèª
â”œâ”€ ãƒ¦ãƒ¼ã‚¶ãƒ¼é€šçŸ¥
â””â”€ ãƒã‚¹ãƒˆãƒ¢ãƒ¼ãƒ†ãƒ ä½œæˆ
```

#### ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†

```python
from enum import Enum
from dataclasses import dataclass
from datetime import datetime
from typing import List, Optional

class IncidentSeverity(Enum):
    P0 = "critical"
    P1 = "high"
    P2 = "medium"
    P3 = "low"

class IncidentStatus(Enum):
    OPEN = "open"
    INVESTIGATING = "investigating"
    IDENTIFIED = "identified"
    MONITORING = "monitoring"
    RESOLVED = "resolved"

@dataclass
class Incident:
    id: str
    title: str
    description: str
    severity: IncidentSeverity
    status: IncidentStatus
    created_at: datetime
    updated_at: datetime
    assigned_to: Optional[str] = None
    tags: List[str] = None
    affected_users: int = 0

class IncidentManager:
    """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†"""

    @staticmethod
    async def create_incident(
        title: str,
        description: str,
        severity: IncidentSeverity,
        tags: List[str] = None
    ) -> Incident:
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆä½œæˆ"""
        incident = Incident(
            id=generate_incident_id(),
            title=title,
            description=description,
            severity=severity,
            status=IncidentStatus.OPEN,
            created_at=datetime.utcnow(),
            updated_at=datetime.utcnow(),
            tags=tags or []
        )

        await save_incident(incident)

        # é‡è¦åº¦ã«å¿œã˜ãŸé€šçŸ¥
        if severity in [IncidentSeverity.P0, IncidentSeverity.P1]:
            await send_critical_alert(incident)

        return incident

    @staticmethod
    async def update_incident_status(
        incident_id: str,
        new_status: IncidentStatus,
        update_message: str
    ):
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆçŠ¶æ³æ›´æ–°"""
        incident = await get_incident(incident_id)
        incident.status = new_status
        incident.updated_at = datetime.utcnow()

        await save_incident(incident)
        await post_status_update(incident, update_message)

        # è§£æ±ºæ™‚ã®å‡¦ç†
        if new_status == IncidentStatus.RESOLVED:
            await schedule_postmortem(incident)
```

### ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

#### Blue-Green ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

```yaml
# Cloud Run Blue-Green ãƒ‡ãƒ—ãƒ­ã‚¤
steps:
  # 1. Greenç’°å¢ƒã«ãƒ‡ãƒ—ãƒ­ã‚¤
  - name: 'gcr.io/cloud-builders/gcloud'
    args:
      - 'run'
      - 'deploy'
      - 'bondpoint-api-green'
      - '--image'
      - 'gcr.io/$PROJECT_ID/bondpoint-api:$COMMIT_SHA'
      - '--region'
      - 'asia-northeast1'
      - '--no-traffic'

  # 2. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
  - name: 'gcr.io/cloud-builders/curl'
    args:
      - '-f'
      - 'https://bondpoint-api-green-xyz.a.run.app/health'

  # 3. ã‚¹ãƒ¢ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # APIå‹•ä½œç¢ºèª
        response=$(curl -s https://bondpoint-api-green-xyz.a.run.app/api/v1/health)
        if [[ "$response" != *"healthy"* ]]; then
          echo "Health check failed"
          exit 1
        fi

  # 4. ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯åˆ‡ã‚Šæ›¿ãˆï¼ˆæ®µéšçš„ï¼‰
  - name: 'gcr.io/cloud-builders/gcloud'
    args:
      - 'run'
      - 'services'
      - 'update-traffic'
      - 'bondpoint-api'
      - '--to-revisions'
      - 'bondpoint-api-green=10'
      - '--region'
      - 'asia-northeast1'

  # 5. ç›£è¦–æœŸé–“ï¼ˆ5åˆ†ï¼‰
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        sleep 300
        # ã‚¨ãƒ©ãƒ¼ç‡ãƒã‚§ãƒƒã‚¯
        error_rate=$(gcloud monitoring metrics list --filter="metric.type=custom.googleapis.com/error_rate" --format="value(points[0].value.doubleValue)")
        if (( $(echo "$error_rate > 0.01" | bc -l) )); then
          echo "Error rate too high: $error_rate"
          # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
          gcloud run services update-traffic bondpoint-api --to-revisions bondpoint-api-blue=100
          exit 1
        fi

  # 6. å®Œå…¨åˆ‡ã‚Šæ›¿ãˆ
  - name: 'gcr.io/cloud-builders/gcloud'
    args:
      - 'run'
      - 'services'
      - 'update-traffic'
      - 'bondpoint-api'
      - '--to-revisions'
      - 'bondpoint-api-green=100'
```

### ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»å¾©æ—§

#### è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

```bash
#!/bin/bash
# daily_backup.sh

set -e

# å¤‰æ•°è¨­å®š
PROJECT_ID="bondpoint-prod"
DB_INSTANCE="bondpoint-db"
BUCKET="bondpoint-backups"
DATE=$(date +%Y%m%d_%H%M%S)

echo "Starting backup at $(date)"

# 1. Cloud SQL ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
echo "Creating Cloud SQL backup..."
gcloud sql backups create \
  --instance=$DB_INSTANCE \
  --description="Daily backup $DATE" \
  --project=$PROJECT_ID

# 2. Firestore ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
echo "Exporting Firestore data..."
gcloud firestore export gs://$BUCKET/firestore/$DATE \
  --project=$PROJECT_ID

# 3. Cloud Storage ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
echo "Backing up user data..."
gsutil -m cp -r gs://bondpoint-user-images gs://$BUCKET/user-images/$DATE/

# 4. Secret Manager ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
echo "Backing up secrets metadata..."
gcloud secrets list --format="value(name)" | while read secret; do
  gcloud secrets describe $secret --format=json > /tmp/${secret}.json
done
gsutil cp /tmp/*.json gs://$BUCKET/secrets/$DATE/

# 5. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼
echo "Verifying backups..."
gsutil ls gs://$BUCKET/firestore/$DATE/ > /dev/null
gsutil ls gs://$BUCKET/user-images/$DATE/ > /dev/null

# 6. å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤ï¼ˆ30æ—¥ä»¥ä¸Šï¼‰
echo "Cleaning up old backups..."
gsutil -m rm -r gs://$BUCKET/firestore/$(date -d '30 days ago' +%Y%m%d)_* || true
gsutil -m rm -r gs://$BUCKET/user-images/$(date -d '30 days ago' +%Y%m%d)_* || true

echo "Backup completed successfully at $(date)"

# 7. çµæœé€šçŸ¥
curl -X POST https://hooks.slack.com/services/... \
  -H 'Content-type: application/json' \
  --data "{\"text\":\"âœ… Daily backup completed: $DATE\"}"
```

---

## ğŸ”§ ä¿å®ˆãƒ»é‹ç”¨æ‰‹é †

### å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

#### æœˆæ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

```bash
#!/bin/bash
# monthly_maintenance.sh

echo "=== Monthly Maintenance $(date) ==="

# 1. ä¾å­˜é–¢ä¿‚æ›´æ–°
echo "Updating dependencies..."
pip-review --auto
npm audit fix

# 2. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‘ãƒƒãƒé©ç”¨
echo "Applying security patches..."
gcloud sql patches apply --patch=... --instance=bondpoint-db

# 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–
echo "Optimizing database..."
psql $DATABASE_URL << EOF
VACUUM ANALYZE;
REINDEX DATABASE bondpoint;
EOF

# 4. å¤ã„ãƒ‡ãƒ¼ã‚¿å‰Šé™¤
echo "Cleaning up old data..."
python scripts/cleanup_old_data.py

# 5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
echo "Running performance tests..."
locust --headless -u 100 -r 10 -t 300s --host=https://api.bondpoint.com

# 6. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ
echo "Testing backup restoration..."
./scripts/test_backup_restore.sh

# 7. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³
echo "Running security scan..."
nmap -sV api.bondpoint.com
bandit -r app/

echo "=== Maintenance completed ==="
```

### ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°

#### æˆé•·äºˆæ¸¬

```python
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression

class CapacityPlanner:
    """ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£è¨ˆç”»"""

    def __init__(self):
        self.user_growth_model = LinearRegression()
        self.load_prediction_model = LinearRegression()

    def analyze_growth_trend(self, historical_data: pd.DataFrame):
        """æˆé•·ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ã®æˆé•·äºˆæ¸¬
        X = historical_data[['days_since_launch']].values
        y = historical_data['daily_active_users'].values

        self.user_growth_model.fit(X, y)

        # 3ãƒ¶æœˆå¾Œã®äºˆæ¸¬
        future_days = np.array([[90]])  # 90æ—¥å¾Œ
        predicted_users = self.user_growth_model.predict(future_days)[0]

        return {
            'predicted_dau_3months': int(predicted_users),
            'growth_rate_per_day': self.user_growth_model.coef_[0],
            'confidence_score': self.user_growth_model.score(X, y)
        }

    def recommend_scaling(self, current_metrics: dict, predicted_load: dict):
        """ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ¨å¥¨"""
        recommendations = []

        # Cloud Run æ¨å¥¨
        if predicted_load['requests_per_second'] > 500:
            recommendations.append({
                'service': 'Cloud Run',
                'action': 'Increase max instances to 200',
                'reason': 'High request volume predicted'
            })

        # Cloud SQL æ¨å¥¨
        if predicted_load['db_connections'] > current_metrics['max_connections'] * 0.8:
            recommendations.append({
                'service': 'Cloud SQL',
                'action': 'Upgrade to db-n1-standard-2',
                'reason': 'Connection pool will be exhausted'
            })

        return recommendations
```

---

**Next**: [[11-é–‹ç™ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«]] - 12é€±é–“ã®è©³ç´°å®Ÿè£…è¨ˆç”»